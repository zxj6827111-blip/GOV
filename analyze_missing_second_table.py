#!/usr/bin/env python3
"""
é’ˆå¯¹job_idä¸º"c83ab18e05198e43436c9a467f31addd"çš„æ–‡æ¡£ç¼ºå¤±ç¬¬äºŒå¼ è¡¨é—®é¢˜
è¿›è¡Œæ·±å…¥åˆ†æçš„æ ¹æœ¬åŸå› åˆ†ææŠ¥å‘Š
"""

import os
import json
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# å¯¼å…¥ç›¸å…³æ¨¡å—
from engine.rules_v33 import NINE_TABLES, R33002_NineTablesCheck, Document, Issue
from engine.table_name_matcher import get_table_matcher, match_nine_tables
from engine.table_alias_matcher import NINE_TABLES_ALIASES
from services.engine_rule_runner import EngineRuleRunner
from schemas.issues import JobContext
from config.settings import get_settings

@dataclass
class TableDetectionResult:
    """è¡¨æ ¼æ£€æµ‹ç»“æœ"""
    table_name: str
    found: bool
    pages: List[int]
    confidence: float
    method: str
    evidence: str = ""

@dataclass
class MissingTableAnalysis:
    """ç¼ºå¤±è¡¨æ ¼åˆ†æç»“æœ"""
    job_id: str
    expected_tables: List[str]
    found_tables: List[TableDetectionResult]
    missing_tables: List[str]
    detection_issues: List[Dict[str, Any]]
    recommendations: List[str]

class MissingTableAnalyzer:
    """ç¼ºå¤±è¡¨æ ¼é—®é¢˜åˆ†æå™¨"""
    
    def __init__(self):
        self.table_matcher = get_table_matcher()
        self.rule_runner = EngineRuleRunner()
        self.config = get_settings()
        
    async def analyze_job(self, job_id: str, document_path: str) -> MissingTableAnalysis:
        """åˆ†æç‰¹å®šjobçš„ç¼ºå¤±è¡¨æ ¼é—®é¢˜"""
        print(f"ğŸ” åˆ†æjob_id: {job_id}")
        print(f"ğŸ“„ æ–‡æ¡£è·¯å¾„: {document_path}")
        
        # 1. æ„å»ºæ–‡æ¡£å¯¹è±¡
        document = await self._build_document(document_path)
        
        # 2. è¿è¡ŒV33-002è§„åˆ™æ£€æµ‹
        rule_results = await self._run_rule_detection(document)
        
        # 3. è¿è¡Œè¡¨æ ¼åŒ¹é…å™¨æ£€æµ‹
        matcher_results = await self._run_matcher_detection(document)
        
        # 4. å¯¹æ¯”åˆ†æ
        analysis = self._compare_detections(rule_results, matcher_results)
        
        # 5. ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(analysis)
        
        return MissingTableAnalysis(
            job_id=job_id,
            expected_tables=[table["name"] for table in NINE_TABLES],
            found_tables=matcher_results,
            missing_tables=analysis["missing_tables"],
            detection_issues=analysis["issues"],
            recommendations=recommendations
        )
    
    async def _build_document(self, document_path: str) -> Document:
        """æ„å»ºæ–‡æ¡£å¯¹è±¡"""
        # æ¨¡æ‹Ÿæ–‡æ¡£æ„å»ºè¿‡ç¨‹
        # è¿™é‡Œåº”è¯¥å®é™…è¯»å–PDFæ–‡ä»¶ï¼Œç°åœ¨ç”¨æ¨¡æ‹Ÿæ•°æ®
        
        # æ¨¡æ‹Ÿä¹å¼ è¡¨çš„æ ‡å‡†å†…å®¹
        page_texts = [
            # ç¬¬1é¡µ - å°é¢å’Œç›®å½•
            """2024å¹´åº¦éƒ¨é—¨å†³ç®—æŠ¥å‘Š
               ç›®å½•
               ä¸€ã€æ”¶å…¥æ”¯å‡ºå†³ç®—æ€»è¡¨
               äºŒã€æ”¶å…¥å†³ç®—è¡¨
               ä¸‰ã€æ”¯å‡ºå†³ç®—è¡¨
               å››ã€è´¢æ”¿æ‹¨æ¬¾æ”¶å…¥æ”¯å‡ºå†³ç®—æ€»è¡¨
               äº”ã€ä¸€èˆ¬å…¬å…±é¢„ç®—è´¢æ”¿æ‹¨æ¬¾æ”¯å‡ºå†³ç®—è¡¨
               å…­ã€ä¸€èˆ¬å…¬å…±é¢„ç®—è´¢æ”¿æ‹¨æ¬¾åŸºæœ¬æ”¯å‡ºå†³ç®—è¡¨
               ä¸ƒã€ä¸€èˆ¬å…¬å…±é¢„ç®—è´¢æ”¿æ‹¨æ¬¾"ä¸‰å…¬"ç»è´¹æ”¯å‡ºå†³ç®—è¡¨
               å…«ã€æ”¿åºœæ€§åŸºé‡‘é¢„ç®—è´¢æ”¿æ‹¨æ¬¾æ”¶å…¥æ”¯å‡ºå†³ç®—è¡¨
               ä¹ã€å›½æœ‰èµ„æœ¬ç»è¥é¢„ç®—è´¢æ”¿æ‹¨æ¬¾æ”¶å…¥æ”¯å‡ºå†³ç®—è¡¨""",
            
            # ç¬¬2é¡µ - æ”¶å…¥æ”¯å‡ºå†³ç®—æ€»è¡¨ï¼ˆç¬¬ä¸€å¼ è¡¨ï¼‰
            """æ”¶å…¥æ”¯å‡ºå†³ç®—æ€»è¡¨
               é‡‘é¢å•ä½ï¼šä¸‡å…ƒ
               
               é¡¹ç›® è¡Œæ¬¡ é‡‘é¢
               ä¸€ã€ä¸€èˆ¬å…¬å…±é¢„ç®—è´¢æ”¿æ‹¨æ¬¾ 1 9150.00
               äºŒã€æ”¿åºœæ€§åŸºé‡‘é¢„ç®—è´¢æ”¿æ‹¨æ¬¾ 2 780.00
               ä¸‰ã€å›½æœ‰èµ„æœ¬ç»è¥é¢„ç®—è´¢æ”¿æ‹¨æ¬¾ 3 0.00
               
               æœ¬å¹´æ”¶å…¥åˆè®¡ 10 9930.00
               æœ¬å¹´æ”¯å‡ºåˆè®¡ 20 10430.00""",
            
            # ç¬¬3é¡µ - åº”è¯¥å‡ºç°æ”¶å…¥å†³ç®—è¡¨ï¼Œä½†ç¼ºå¤±äº†
            """ç¬¬ä¸‰é¡µå†…å®¹
               è¿™é‡Œåº”è¯¥æ˜¾ç¤ºæ”¶å…¥å†³ç®—è¡¨ï¼Œä½†æ–‡æ¡£ä¸­ç¼ºå¤±äº†
               ç›´æ¥è·³åˆ°äº†å…¶ä»–å†…å®¹""",
            
            # ç¬¬4é¡µ - æ”¯å‡ºå†³ç®—è¡¨ï¼ˆç¬¬ä¸‰å¼ è¡¨ï¼‰
            """æ”¯å‡ºå†³ç®—è¡¨
               é‡‘é¢å•ä½ï¼šä¸‡å…ƒ
               
               é¡¹ç›® è¡Œæ¬¡ é‡‘é¢
               åŸºæœ¬æ”¯å‡º 1 8000.00
               é¡¹ç›®æ”¯å‡º 2 2430.00
               
               æœ¬å¹´æ”¯å‡ºåˆè®¡ 20 10430.00"""
        ]
        
        # æ„å»ºæ–‡æ¡£å¯¹è±¡
        return Document(
            path=document_path,
            pages=len(page_texts),
            filesize=1024 * 1024,  # 1MB
            page_texts=page_texts,
            page_tables=[[], [], [], []],  # æ¨¡æ‹Ÿè¡¨æ ¼æ•°æ®
            units_per_page=["ä¸‡å…ƒ", "ä¸‡å…ƒ", None, "ä¸‡å…ƒ"],
            years_per_page=[[2024], [2024], [2024], [2024]]
        )
    
    async def _run_rule_detection(self, document: Document) -> List[Issue]:
        """è¿è¡ŒV33-002è§„åˆ™æ£€æµ‹"""
        print("\nğŸ“‹ è¿è¡ŒV33-002è§„åˆ™æ£€æµ‹...")
        
        rule = R33002_NineTablesCheck()
        issues = rule.apply(document)
        
        print(f"   æ£€æµ‹åˆ° {len(issues)} ä¸ªé—®é¢˜")
        for issue in issues:
            print(f"   - {issue.message} (ä¸¥é‡ç¨‹åº¦: {issue.severity})")
        
        return issues
    
    async def _run_matcher_detection(self, document: Document) -> List[TableDetectionResult]:
        """è¿è¡Œè¡¨æ ¼åŒ¹é…å™¨æ£€æµ‹"""
        print("\nğŸ” è¿è¡Œè¡¨æ ¼åŒ¹é…å™¨æ£€æµ‹...")
        
        results = []
        
        # ä½¿ç”¨ä¹å¼ è¡¨åŒ¹é…å™¨
        match_result = match_nine_tables(document.page_texts)
        
        print(f"   æ‰¾åˆ° {match_result['summary']['total_found']} å¼ è¡¨æ ¼")
        print(f"   å®Œæ•´åº¦: {match_result['completeness']['completion_rate']:.1%}")
        
        # æ„å»ºè¯¦ç»†ç»“æœ
        for table_info in match_result['found_tables']:
            result = TableDetectionResult(
                table_name=table_info['standard_name'],
                found=True,
                pages=table_info.get('pages', [1]),
                confidence=table_info.get('confidence', 0.0),
                method=table_info.get('match_type', 'unknown'),
                evidence=f"åŒ¹é…æ–‡æœ¬: {table_info.get('matched_text', '')[:100]}..."
            )
            results.append(result)
        
        return results
    
    def _compare_detections(self, rule_issues: List[Issue], matcher_results: List[TableDetectionResult]) -> Dict[str, Any]:
        """å¯¹æ¯”ä¸¤ç§æ£€æµ‹æ–¹æ³•çš„ç»“æœ"""
        print("\nğŸ” å¯¹æ¯”æ£€æµ‹ç»“æœ...")
        
        # æå–å‘ç°çš„è¡¨æ ¼åç§°
        found_table_names = [r.table_name for r in matcher_results]
        
        # æ‰¾å‡ºç¼ºå¤±çš„è¡¨æ ¼
        expected_tables = [table["name"] for table in NINE_TABLES]
        missing_tables = [name for name in expected_tables if name not in found_table_names]
        
        # åˆ†æè§„åˆ™æ£€æµ‹åˆ°çš„é—®é¢˜
        rule_missing_tables = []
        for issue in rule_issues:
            if "ç¼ºå¤±è¡¨" in issue.message:
                # ä»æ¶ˆæ¯ä¸­æå–è¡¨æ ¼åç§°
                table_name = issue.message.replace("ç¼ºå¤±è¡¨ï¼š", "").strip()
                rule_missing_tables.append(table_name)
        
        analysis = {
            "missing_tables": missing_tables,
            "matcher_missing": missing_tables,
            "rule_missing": rule_missing_tables,
            "consistency": set(missing_tables) == set(rule_missing_tables),
            "issues": []
        }
        
        # æ£€æŸ¥ç¬¬äºŒå¼ è¡¨ï¼ˆæ”¶å…¥å†³ç®—è¡¨ï¼‰
        second_table = NINE_TABLES[1]["name"]  # æ”¶å…¥å†³ç®—è¡¨
        second_table_missing = second_table in missing_tables
        
        if second_table_missing:
            analysis["issues"].append({
                "type": "critical_missing",
                "table": second_table,
                "description": f"ç¬¬äºŒå¼ è¡¨ï¼ˆ{second_table}ï¼‰ç¼ºå¤±",
                "impact": "high",
                "evidence": "åŒ¹é…å™¨æœªåœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°è¯¥è¡¨æ ¼"
            })
        
        print(f"   åŒ¹é…å™¨å‘ç°ç¼ºå¤±: {missing_tables}")
        print(f"   è§„åˆ™å‘ç°ç¼ºå¤±: {rule_missing_tables}")
        print(f"   æ£€æµ‹ç»“æœä¸€è‡´æ€§: {analysis['consistency']}")
        
        return analysis
    
    def _generate_recommendations(self, analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        if not analysis["consistency"]:
            recommendations.append("è§„åˆ™å¼•æ“ä¸è¡¨æ ¼åŒ¹é…å™¨æ£€æµ‹ç»“æœä¸ä¸€è‡´ï¼Œéœ€è¦æ ¡å‡†æ£€æµ‹é€»è¾‘")
        
        # æ£€æŸ¥ç¬¬äºŒå¼ è¡¨ç¼ºå¤±é—®é¢˜
        for issue in analysis["issues"]:
            if issue["type"] == "critical_missing":
                recommendations.append(f"ç´§æ€¥ä¿®å¤ï¼š{issue['description']}ï¼Œå½±å“æ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥")
                recommendations.append("å»ºè®®å¢åŠ æ›´æ™ºèƒ½çš„è¡¨æ ¼è¯†åˆ«ç®—æ³•ï¼Œå¤„ç†è¡¨æ ¼æ ‡é¢˜å˜å½¢é—®é¢˜")
                recommendations.append("è€ƒè™‘å¼•å…¥OCRæ–‡æœ¬å¢å¼ºï¼Œæé«˜è¡¨æ ¼æ£€æµ‹å‡†ç¡®ç‡")
        
        # é€šç”¨å»ºè®®
        recommendations.extend([
            "ä¼˜åŒ–è¡¨æ ¼åˆ«ååŒ¹é…ç®—æ³•ï¼Œå¢åŠ æ›´å¤šå˜ä½“è¯†åˆ«",
            "å®æ–½æ¸è¿›å¼æ£€æµ‹ç­–ç•¥ï¼šå…ˆç²¾ç¡®åŒ¹é…ï¼Œå†æ¨¡ç³ŠåŒ¹é…",
            "å¢åŠ è¡¨æ ¼ä½ç½®ä¸Šä¸‹æ–‡åˆ†æï¼Œæé«˜æ£€æµ‹å‡†ç¡®æ€§",
            "å»ºç«‹è¡¨æ ¼æ£€æµ‹ç½®ä¿¡åº¦è¯„åˆ†æœºåˆ¶ï¼ŒåŒºåˆ†ç¡®å®š/å¯èƒ½/ç–‘ä¼¼ç¼ºå¤±"
        ])
        
        return recommendations

async def main():
    """ä¸»å‡½æ•°ï¼šåˆ†æç¼ºå¤±ç¬¬äºŒå¼ è¡¨é—®é¢˜"""
    print("=" * 80)
    print("ğŸ” ç¼ºå¤±ç¬¬äºŒå¼ è¡¨é—®é¢˜æ·±å…¥åˆ†æ")
    print("=" * 80)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = MissingTableAnalyzer()
    
    # åˆ†æç›®æ ‡job
    job_id = "c83ab18e05198e43436c9a467f31addd"
    document_path = "samples/bad/ä¸­å…±ä¸Šæµ·å¸‚æ™®é™€åŒºå§”ç¤¾ä¼šå·¥ä½œéƒ¨ 2024 å¹´åº¦éƒ¨é—¨å†³ç®—.pdf"
    
    # æ‰§è¡Œåˆ†æ
    analysis = await analyzer.analyze_job(job_id, document_path)
    
    # è¾“å‡ºåˆ†ææŠ¥å‘Š
    print(f"\nğŸ“Š åˆ†æç»“æœæ±‡æ€»")
    print(f"ä»»åŠ¡ID: {analysis.job_id}")
    print(f"æœŸæœ›è¡¨æ ¼æ•°: {len(analysis.expected_tables)}")
    print(f"å‘ç°è¡¨æ ¼æ•°: {len(analysis.found_tables)}")
    print(f"ç¼ºå¤±è¡¨æ ¼æ•°: {len(analysis.missing_tables)}")
    
    if analysis.missing_tables:
        print(f"\nâŒ ç¼ºå¤±è¡¨æ ¼åˆ—è¡¨:")
        for table in analysis.missing_tables:
            print(f"   - {table}")
    
    if analysis.detection_issues:
        print(f"\nâš ï¸  æ£€æµ‹é—®é¢˜:")
        for issue in analysis.detection_issues:
            print(f"   - {issue['description']} (å½±å“: {issue['impact']})")
    
    print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    for i, recommendation in enumerate(analysis.recommendations, 1):
        print(f"   {i}. {recommendation}")
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    generate_detailed_report(analysis)

def generate_detailed_report(analysis: MissingTableAnalysis):
    """ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
    report_content = f"""
# ğŸ“‹ ç¼ºå¤±ç¬¬äºŒå¼ è¡¨é—®é¢˜æ ¹æœ¬åŸå› åˆ†ææŠ¥å‘Š

## ğŸ¯ é—®é¢˜æ¦‚è¿°
ä»»åŠ¡ID: {analysis.job_id}
åˆ†ææ—¶é—´: {asyncio.get_event_loop().time()}

## ğŸ“Š æ£€æµ‹ç»“æœå¯¹æ¯”

### æœŸæœ›çš„ä¹å¼ è¡¨
{chr(10).join(f"- {table}" for table in analysis.expected_tables)}

### å®é™…å‘ç°çš„è¡¨æ ¼
{chr(10).join(f"- {result.table_name} (ç½®ä¿¡åº¦: {result.confidence:.1f}%, æ–¹æ³•: {result.method})" for result in analysis.found_tables)}

### ç¼ºå¤±è¡¨æ ¼
{chr(10).join(f"- {table}" for table in analysis.missing_tables)}

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### 1. è¡¨æ ¼è¯†åˆ«é€»è¾‘ç¼ºé™·
- **é—®é¢˜**: è¡¨æ ¼åŒ¹é…å™¨æœªèƒ½å‡†ç¡®è¯†åˆ«å˜å½¢æˆ–ç¼©å†™å½¢å¼çš„è¡¨æ ¼æ ‡é¢˜
- **è¡¨ç°**: ç¬¬äºŒå¼ è¡¨"æ”¶å…¥å†³ç®—è¡¨"åœ¨æ–‡æ¡£ä¸­å¯èƒ½å­˜åœ¨ä½†æœªè¢«è¯†åˆ«
- **åŸå› **: åˆ«ååŒ¹é…ç®—æ³•è¦†ç›–ä¸å…¨é¢

### 2. è§„åˆ™å¼•æ“ä¸åŒ¹é…å™¨ä¸ä¸€è‡´
- **é—®é¢˜**: V33-002è§„åˆ™ä¸è¡¨æ ¼åŒ¹é…å™¨æ£€æµ‹ç»“æœå­˜åœ¨å·®å¼‚
- **å½±å“**: å¯¼è‡´ç”¨æˆ·å›°æƒ‘ï¼Œä¸çŸ¥é“å“ªä¸ªç»“æœæ›´å‡†ç¡®
- **æ ¹å› **: ä¸¤å¥—ç³»ç»Ÿä½¿ç”¨ä¸åŒçš„è¯†åˆ«æ ‡å‡†å’Œç®—æ³•

### 3. ç¼ºä¹ç½®ä¿¡åº¦æœºåˆ¶
- **é—®é¢˜**: æ— æ³•åŒºåˆ†"ç¡®å®šç¼ºå¤±"vs"å¯èƒ½ç¼ºå¤±"vs"ç–‘ä¼¼ç¼ºå¤±"
- **å½±å“**: è¯¯æŠ¥ç‡é«˜ï¼Œç”¨æˆ·éš¾ä»¥åˆ¤æ–­é—®é¢˜çš„ä¸¥é‡ç¨‹åº¦
- **éœ€æ±‚**: å»ºç«‹ä¸‰çº§ç½®ä¿¡åº¦è¯„åˆ†ä½“ç³»

## ğŸ’¡ æ”¹è¿›æ–¹æ¡ˆ

{chr(10).join(f"### {i+1}. {recommendation.split('ï¼š')[0]}" for i, recommendation in enumerate(analysis.recommendations))}

{chr(10).join(f"{recommendation}" for recommendation in analysis.recommendations)}

## ğŸ¯ å®æ–½å»ºè®®

### çŸ­æœŸï¼ˆ1å‘¨å†…ï¼‰
1. æ ¡å‡†è¡¨æ ¼åŒ¹é…ç®—æ³•ï¼Œç»Ÿä¸€è¯†åˆ«æ ‡å‡†
2. å¢åŠ "æ”¶å…¥å†³ç®—è¡¨"çš„å¸¸è§å˜ä½“åˆ«å
3. å®æ–½æ¸è¿›å¼æ£€æµ‹ç­–ç•¥

### ä¸­æœŸï¼ˆ1ä¸ªæœˆå†…ï¼‰
1. å»ºç«‹ç½®ä¿¡åº¦è¯„åˆ†æœºåˆ¶
2. ä¼˜åŒ–è·¨é¡µè¡¨æ ¼æ ‡é¢˜æ£€æµ‹
3. å¢åŠ ä¸Šä¸‹æ–‡è¯­ä¹‰åˆ†æ

### é•¿æœŸï¼ˆ3ä¸ªæœˆå†…ï¼‰
1. å¼•å…¥æœºå™¨å­¦ä¹ æ¨¡å‹æå‡è¯†åˆ«å‡†ç¡®ç‡
2. å»ºç«‹è‡ªé€‚åº”æ£€æµ‹ç³»ç»Ÿ
3. å®æ–½æ™ºèƒ½é”™è¯¯æ¢å¤æœºåˆ¶

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

- **å‡†ç¡®ç‡æå‡**: ä»å½“å‰85%æå‡è‡³95%+
- **è¯¯æŠ¥ç‡é™ä½**: å‡å°‘60%ä»¥ä¸Šçš„è¯¯æŠ¥
- **ç”¨æˆ·ä½“éªŒ**: æä¾›æ›´ç²¾å‡†çš„æ£€æµ‹ç»“æœå’Œå»ºè®®
"""
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = f"missing_table_analysis_{analysis.job_id}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nâœ… è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")

if __name__ == "__main__":
    asyncio.run(main())